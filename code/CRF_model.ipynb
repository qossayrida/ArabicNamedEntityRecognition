{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-EVE       0.99      0.98      0.98      1850\n",
      "       B-LAN       1.00      0.86      0.92       139\n",
      "       B-LOC       0.95      0.96      0.95      8130\n",
      "       B-MON       0.99      0.90      0.94       187\n",
      "       B-NUM       0.97      0.94      0.95      1426\n",
      "       B-ORG       0.98      0.97      0.98     11150\n",
      "       B-PER       0.99      0.95      0.97      8106\n",
      "      B-TIME       0.99      0.98      0.98     11014\n",
      "       I-EVE       0.98      0.98      0.98      4107\n",
      "       I-LAN       1.00      1.00      1.00         4\n",
      "       I-LOC       0.98      0.99      0.98      6121\n",
      "       I-MON       0.99      1.00      1.00       314\n",
      "       I-NUM       0.97      0.99      0.98       544\n",
      "       I-ORG       0.98      0.99      0.98     16342\n",
      "       I-PER       0.99      0.98      0.98      7635\n",
      "      I-TIME       0.97      0.99      0.98     39600\n",
      "           O       0.99      0.99      0.99    274329\n",
      "\n",
      "    accuracy                           0.99    390998\n",
      "   macro avg       0.98      0.97      0.97    390998\n",
      "weighted avg       0.99      0.99      0.99    390998\n",
      "\n",
      "[('سيادة', 'O'), ('الرئيس', 'O'), ('محمود', 'B-PER'), ('عباس', 'I-PER')]\n",
      "CRF model saved to crf_model.joblib\n"
     ]
    }
   ],
   "source": [
    "data = []  # To store (sentence, labels) tuples\n",
    "sentence = []\n",
    "labels = []\n",
    "\n",
    "with open('data/train_cleaned.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Split sentences at empty lines\n",
    "        if not line:\n",
    "            if sentence:  # If we have a completed sentence\n",
    "                data.append((\" \".join(sentence), labels))\n",
    "                sentence = []\n",
    "                labels = []\n",
    "            continue\n",
    "        \n",
    "        # Split the word and its label\n",
    "        word, label = line.rsplit(' ', 1)\n",
    "        sentence.append(word)\n",
    "        labels.append(label)\n",
    "\n",
    "# Add the last sentence if file doesn't end with a blank line\n",
    "if sentence:\n",
    "    data.append((\" \".join(sentence), labels))\n",
    "    \n",
    "def extract_features(tokens):\n",
    "    features = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        token_features = {\n",
    "            'word': token,\n",
    "            'is_digit': token.isdigit(),\n",
    "            'prefix1': token[:1],\n",
    "            'suffix1': token[-1:],\n",
    "            'is_arabic': all('\\u0600' <= char <= '\\u06FF' for char in token),\n",
    "        }\n",
    "        if i > 0:\n",
    "            token_features['prev_word'] = tokens[i - 1]\n",
    "        else:\n",
    "            token_features['prev_word'] = '<START>'\n",
    "        if i < len(tokens) - 1:\n",
    "            token_features['next_word'] = tokens[i + 1]\n",
    "        else:\n",
    "            token_features['next_word'] = '<END>'\n",
    "        features.append(token_features)\n",
    "    return features\n",
    "\n",
    "# Prepare X (features) and y (labels)\n",
    "X = [extract_features(sentence.split()) for sentence, labels in data]\n",
    "y = [labels for sentence, labels in data]\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X, y)\n",
    "\n",
    "\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "y_pred = crf.predict(X)\n",
    "print(flat_classification_report(y, y_pred))\n",
    "\n",
    "\n",
    "new_sentence = \"سيادة الرئيس محمود عباس\"\n",
    "new_tokens = new_sentence.split()  # Tokenize manually or use a tokenizer\n",
    "new_features = extract_features(new_tokens)\n",
    "\n",
    "predictions = crf.predict([new_features])\n",
    "print(list(zip(new_tokens, predictions[0])))\n",
    "\n",
    "\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "# Save the trained CRF model to a file\n",
    "dump(crf, 'model/crf_model.joblib')\n",
    "print(\"CRF model saved to crf_model.joblib\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-26T18:30:03.187465600Z",
     "start_time": "2024-12-26T18:29:19.007507400Z"
    }
   },
   "id": "5699a44a746e1c67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
