{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb8db590fad6ab31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import the data and prepare it for training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a08be24988161ef"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../backend')\n",
    "from backend import assemblage\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "data = assemblage.load_data(\"../data/train_cleaned.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T14:33:08.278350900Z",
     "start_time": "2025-01-04T14:33:07.978943700Z"
    }
   },
   "id": "7df917d867adde25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the Naive Bayes model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18035a8fa4ec5103"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "X = []  # Feature dictionaries\n",
    "y = []  # Labels\n",
    "for sentence, labels in data:\n",
    "    tokens = sentence.split()\n",
    "    for idx, label in enumerate(labels):\n",
    "        X.append(assemblage.extract_features_for_DT_NB(tokens, idx))\n",
    "        y.append(label)\n",
    "\n",
    "\n",
    "# Convert features to a format suitable for scikit-learn\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_vectorized, y)\n",
    "\n",
    "print(\"Model trained successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T14:33:18.704322200Z",
     "start_time": "2025-01-04T14:33:08.285599800Z"
    }
   },
   "id": "5272da2c0de4cd9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28fb5a55aab9385a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8129811405684939\n",
      "Train Recall: 0.5032359495309404\n",
      "Train Precision: 0.5503921096271913\n",
      "Train F1: 0.4762517205468807\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8102440096724555\n",
      "Test Recall: 0.4808387415465718\n",
      "Test Precision: 0.47164107148267054\n",
      "Test F1: 0.4567870870568938\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.8141777430284076\n",
      "Validation Recall: 0.48862108141621924\n",
      "Validation Precision: 0.4930946666029553\n",
      "Validation F1: 0.4681748860237034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score , f1_score\n",
    "\n",
    "data_test = assemblage.load_data(\"../data/test_cleaned.txt\")\n",
    "data_val = assemblage.load_data(\"../data/val_cleaned.txt\")\n",
    "\n",
    "X_test = []  # Feature dictionaries\n",
    "y_test = []  # Labels\n",
    "for sentence, labels in data_test:\n",
    "    tokens = sentence.split()\n",
    "    for idx, label in enumerate(labels):\n",
    "        X_test.append(assemblage.extract_features_for_DT_NB(tokens, idx))\n",
    "        y_test.append(label)\n",
    "\n",
    "X_val = []  # Feature dictionaries\n",
    "y_val = []  # Labels\n",
    "for sentence, labels in data_val:\n",
    "    tokens = sentence.split()\n",
    "    for idx, label in enumerate(labels):\n",
    "        X_val.append(assemblage.extract_features_for_DT_NB(tokens, idx))\n",
    "        y_val.append(label)\n",
    "        \n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "X_val_vectorized = vectorizer.transform(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "train_predictions = clf.predict(X_vectorized)\n",
    "train_accuracy = clf.score(X_vectorized, y)\n",
    "train_recall = recall_score(y, train_predictions, average='macro', zero_division=0)\n",
    "train_precision = precision_score(y,train_predictions, average='macro', zero_division=0)\n",
    "train_f1 = f1_score(y,train_predictions, average='macro', zero_division=0)\n",
    "\n",
    "test_predictions = clf.predict(X_test_vectorized)\n",
    "test_accuracy = clf.score(X_test_vectorized, y_test)\n",
    "test_recall = recall_score(y_test, test_predictions, average='macro', zero_division=0)\n",
    "test_precision = precision_score(y_test,test_predictions, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(y_test,test_predictions, average='macro', zero_division=0)\n",
    "\n",
    "val_predictions = clf.predict(X_val_vectorized)\n",
    "val_accuracy = clf.score(X_val_vectorized, y_val)\n",
    "val_recall = recall_score(y_val, val_predictions, average='macro', zero_division=0)\n",
    "val_precision = precision_score(y_val,val_predictions, average='macro', zero_division=0)\n",
    "val_f1 = f1_score(y_val,val_predictions, average='macro', zero_division=0)\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Train Recall:\", train_recall)\n",
    "print(\"Train Precision:\", train_precision)\n",
    "print(\"Train F1:\", train_f1)\n",
    "\n",
    "print(\"\\n\\nTest Accuracy:\", test_accuracy)\n",
    "print(\"Test Recall:\", test_recall)\n",
    "print(\"Test Precision:\", test_precision)\n",
    "print(\"Test F1:\", test_f1)\n",
    "\n",
    "print(\"\\n\\nValidation Accuracy:\", val_accuracy)\n",
    "print(\"Validation Recall:\", val_recall)\n",
    "print(\"Validation Precision:\", val_precision)\n",
    "print(\"Validation F1:\", val_f1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T14:33:29.356016600Z",
     "start_time": "2025-01-04T14:33:18.716691900Z"
    }
   },
   "id": "4c11da83eb26c26a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68b889b758136ca0"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully.\n",
      "Predicted Entities:\n",
      "مرحبا: O\n",
      "انا: O\n",
      "اسمي: O\n",
      "قصي: B-PER\n",
      "وانا: O\n",
      "اعيش: O\n",
      "في: O\n",
      "الاردن: B-LOC\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"../model/naive_bayes_ner_model.joblib\")\n",
    "joblib.dump(vectorizer, \"../model/naive_bayes_vectorizer.joblib\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully.\")\n",
    "\n",
    "# Load the model and vectorizer\n",
    "clf_loaded = joblib.load(\"../model/naive_bayes_ner_model.joblib\")\n",
    "vectorizer_loaded = joblib.load(\"../model/naive_bayes_vectorizer.joblib\")\n",
    "\n",
    "# Test the model on a new sentence\n",
    "def predict_entities(sentence, clf, vectorizer):\n",
    "    tokens = sentence.split()\n",
    "    features = [assemblage.extract_features_for_DT_NB(tokens, idx) for idx in range(len(tokens))]\n",
    "    features_vectorized = vectorizer.transform(features)\n",
    "    predictions = clf.predict(features_vectorized)\n",
    "    return list(zip(tokens, predictions))\n",
    "\n",
    "# Example sentence\n",
    "test_sentence = \"مرحبا انا اسمي قصي وانا اعيش في الاردن\"\n",
    "predictions = predict_entities(test_sentence, clf_loaded, vectorizer_loaded)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predicted Entities:\")\n",
    "for token, label in predictions:\n",
    "    print(f\"{token}: {label}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T14:33:30.359618600Z",
     "start_time": "2025-01-04T14:33:29.359934600Z"
    }
   },
   "id": "b282455707993dfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
